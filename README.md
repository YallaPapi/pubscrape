# Bing Search Engine Scraper with Botasaurus and Agency Swarm

A production-ready, AI-powered contact discovery system that uses Bing search to find business emails at scale while maintaining compliance and minimizing detection.

## ğŸ¯ Overview

This system combines **Botasaurus** for anti-detection browser automation with **Agency Swarm** for multi-agent AI orchestration to create a robust, scalable email scraping solution.

### Key Features

- **ğŸ¤– 13 Specialized AI Agents** - Campaign CEO, Query Builder, Bing Navigator, etc.
- **ğŸ›¡ï¸ Advanced Anti-Detection** - User-agent rotation, proxy management, human-like delays
- **âš¡ Rate Limiting & Circuit Breakers** - Smart throttling and adaptive backoff
- **ğŸ“§ Multi-Method Email Extraction** - Regex, obfuscation handling, context scoring
- **ğŸ”§ Configuration-Driven** - YAML configs per campaign
- **ğŸ“Š Comprehensive Monitoring** - Real-time dashboards, metrics, and alerts
- **ğŸ³ Docker Ready** - Full containerization with monitoring stack

### Target Performance

- **500-1000 leads/day** per campaign
- **60-70% SERP extraction** success rate
- **25-35% email discovery** rate on visited sites
- **<10% block rate** with proper configuration

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.10+**
- **Git**
- **Docker & Docker Compose** (optional, for production)
- **Chrome/Chromium** browser

### 1. Clone and Setup

```bash
git clone <repository-url>
cd pubscrape

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
source venv/Scripts/activate
# Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Environment Configuration

Create `.env` file with your API keys:

```bash
# Core AI APIs
ANTHROPIC_API_KEY=your_anthropic_key_here
PERPLEXITY_API_KEY=your_perplexity_key_here
OPENAI_API_KEY=your_openai_key_here

# Optional: Additional APIs
OPENROUTER_API_KEY=your_openrouter_key_here
YOUTUBE_API_KEY=your_youtube_key_here
```

### 3. Verify Installation

```bash
# Test Agency Swarm CLI
agency-swarm --help

# Test Botasaurus installation
python -c "import botasaurus; print('Botasaurus ready!')"

# Run tests
pytest tests/ -v
```

## ğŸ“ Project Structure

```
pubscrape/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/           # Core scraping components
â”‚   â”œâ”€â”€ infra/          # Anti-detection & infrastructure  
â”‚   â”œâ”€â”€ pipeline/       # Data processing pipeline
â”‚   â””â”€â”€ cli/            # Command-line interface
â”œâ”€â”€ configs/            # Campaign configurations
â”œâ”€â”€ out/               # Output files (CSV, JSON, logs)
â”œâ”€â”€ tests/             # Test suites
â”œâ”€â”€ .taskmaster/       # TaskMaster project management
â”œâ”€â”€ venv/             # Virtual environment
â”œâ”€â”€ Dockerfile        # Container configuration
â”œâ”€â”€ docker-compose.yml # Multi-service orchestration
â””â”€â”€ requirements.txt   # Python dependencies
```

## ğŸ¤– Agency Swarm Agents

The system uses 13 specialized AI agents:

1. **CampaignCEO** - Orchestrates campaigns and delegates tasks
2. **QueryBuilder** - Expands search templates to concrete queries  
3. **BingNavigator** - Fetches SERPs via Botasaurus
4. **SerpParser** - Parses SERP HTML to extract URLs
5. **DomainClassifier** - Filters and prioritizes business domains
6. **SiteCrawler** - Visits site pages via Botasaurus
7. **EmailExtractor** - Finds and scores emails using multiple methods
8. **ValidatorDedupe** - Validates and deduplicates emails
9. **Exporter** - Writes CSV/JSON outputs
10. **RateLimitSupervisor** - Enforces rate limits and backoff
11. **AntiDetectionSupervisor** - Manages proxies and sessions
12. **MonitoringAnalyst** - Tracks metrics and raises alerts
13. **IncidentResponder** - Handles operational incidents

## ğŸ“š TaskMaster Integration

This project uses TaskMaster for development workflow:

```bash
# View current tasks
task-master list

# Work on next task
task-master next

# Mark task complete  
task-master set-status --id=X --status=done
```

## ğŸ“„ License

MIT License - Use freely for commercial and personal projects.

---

**Note**: This project evolved from a podcast scraper to a comprehensive Bing scraper. Previous implementations have been archived in the `archived/` directory.

â­ **Star this repo for production-ready contact discovery!**